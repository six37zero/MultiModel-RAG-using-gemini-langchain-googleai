# -*- coding: utf-8 -*-
"""multimodelrag with gemini langchain and google ai studio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-8lA53Fbaj7VPPGSnVX_Nnx7GQWfQOJD
"""

import os
import requests
from PIL import Image

# Commented out IPython magic to ensure Python compatibility.
# %pip install langchain_community

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade  langchain langchain-google-genai "langchain[docarray]" faiss-cpu pypdf

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from IPython.display import display, Markdown

from langchain_google_genai import ChatGoogleGenerativeAI

from langchain_core.messages import HumanMessage, SystemMessage

from langchain.vectorstores import DocArrayInMemorySearch

from langchain_google_genai import GoogleGenerativeAIEmbeddings

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

from langchain.schema.document import Document
from langchain_community.document_loaders import TextLoader

from langchain_text_splitters import CharacterTextSplitter

from langchain_community.vectorstores import FAISS

from google.colab import userdata
GOOGLE_API_KEY=userdata.get('GOOGLE_API')
os.environ["GOOGLE_API"] = GOOGLE_API_KEY

def load_model(model_name):
  if model_name=="gemini-pro":
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")
  else:
    llm=ChatGoogleGenerativeAI(model="gemini-1.5-flash")

  return llm

model_text=load_model("gemini-1.5-flash")

pip install google-generativeai

!pip install google-generativeai # Installs the necessary package
import google.generativeai as genai # Imports the 'genai' module

genai.configure(api_key="AIzaSyCjsrrbpZu4WTAeFr-AF8V9uORS19Kt9ZE")
model = genai.GenerativeModel("gemini-1.5-flash")
response = model.generate_content("Explain how AI works")
print(response.text)

model_text.invoke("please come up with the best funny line.").content



model_text(
    [
        HumanMessage(content="Answer with Simple 'Yes' or 'No'. Question: Is apple a Fruit?")
    ]
).content

def get_image(url,filename,extension):
  content = requests.get(url).content
  with open(f'/content/{filename}.{extension}', 'wb') as f:
    f.write(content)
  image = Image.open(f"/content/{filename}.{extension}")
  image.show()
  return image

image = get_image("https://static.nike.com/a/images/t_PDP_1728_v1/f_auto,q_auto:eco/1705ca64-fbc8-4b79-a451-4ab77760c219/dunk-low-older-shoes-C7T1cx.png",
                  "nike-shoes",
                  "png")

plt.imshow(image)
plt.show()

vision_model=load_model("gemini-pro-vision")

prompt="give me summary of this image in 5 words"

message= HumanMessage(
    content=[
         {
            "type": "text",
            "text": prompt,
        },
        {

            "type": "image_url", "image_url": image
        }
    ]
)

print(vision_model.invoke([message]).content)

loader = TextLoader("/content/nike_shoes.txt")
print(loader.load()[0].page_content)

text=loader.load()[0].page_content

def get_text_chunks_langchain(text):
  text_splitter = CharacterTextSplitter(chunk_size=20, chunk_overlap=10)
  docs = [Document(page_content=x) for x in text_splitter.split_text(text)]
  return docs

docs = get_text_chunks_langchain(text)

embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

vectorstore = FAISS.from_documents(docs,embedding=embeddings)

retriever=vectorstore.as_retriever()

retriever.invoke("Nike slide/sandal.")

from langchain_core.runnables import RunnableLambda, RunnablePassthrough

llm_vision = load_model("gemini-pro-vision")

llm_text = load_model("gemini-pro")

template = """
```
{context}
```

{query}


Provide brief information and store location.
"""

prompt = ChatPromptTemplate.from_template(template)

rag_chain = (
    {"context": retriever, "query": RunnablePassthrough()}
    | prompt
    | llm_text
    | StrOutputParser()
)

result = rag_chain.invoke("can you give me a detail of nike sandal?")

display(Markdown(result))

rag_chain

full_chain = (
    RunnablePassthrough() | llm_vision | StrOutputParser() | rag_chain
)

full_chain

url_1 = "https://static.nike.com/a/images/t_PDP_1728_v1/f_auto,q_auto:eco/252f2db6-d426-4931-80a0-8b7f8f875536/calm-slides-K7mr3W.png"

image = get_image(url_1, "nike3", "png")

plt.imshow(image)
plt.show()

message = HumanMessage(
    content=[
        {
            "type": "text",
            "text": "Provide information on given sandle image Brand and model.",
        },  # You can optionally provide text parts
        {"type": "image_url", "image_url": image},
    ]
)

result = full_chain.invoke([message])

display(Markdown(result))

